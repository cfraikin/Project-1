---
title: "Project 1"
author: "Name: Benjamin Kelly  \n Partner: Chanel Fraikin "
date: "`r Sys.Date()`"
output: 
  pdf_document:
    toc: true
    toc_depth: 3
header-includes:
  - \usepackage{booktabs}
  - \usepackage{longtable}
  - \usepackage{array}
  - \usepackage{multirow}
  - \usepackage{wrapfig}
  - \usepackage{float}
  - \usepackage{colortbl}
  - \usepackage{pdflscape}
  - \usepackage{tabu}
  - \usepackage{threeparttable}
  - \usepackage{threeparttablex}
  - \usepackage[normalem]{ulem}
  - \usepackage{makecell}
  - \usepackage{xcolor}
---
```{r setup, include = FALSE}

#### Load necessary packages ####
# * These packages are not necessary to complete the assignment and or only used 
#   to provide an example. 
packages <- c("knitr", "kableExtra", "magrittr", "readr", "geosphere", "dplyr")

install_me <- packages[!(packages %in% installed.packages()[, "Package"])]
if (length(install_me)) install.packages(install_me)

library(knitr)
library(kableExtra)
library(magrittr)
library(readr)
library(geosphere)
library(dplyr)
```

## Background
The World Health Organization has recently employed a new data science initiative, *CSIT-165*, that uses data science to characterize pandemic diseases. 
*CSIT-165* disseminates data driven analyses to global decision makers.

*CSIT-165* is a conglomerate comprised of two fabricated entities: *Global Health Union (GHU)* and *Private Diagnostic Laboratories (PDL)*. 
Your and your partner's role is to play a data scientist from one of these two entities.

## Data
> [2019 Novel Coronavirus COVID-19 (2019-nCoV) Data Repository by John Hopkins CSSE](https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series)

Data for 2019 Novel Coronavirus is operated by the John Hopkins University Center for Systems Science and Engineering (JHU CSSE).
Data includes daily time series CSV summary tables, including confirmations, recoveries, and deaths. 
Country/region are countries/regions hat conform to World Health Organization (WHO).
Lat and Long refer to coordinates references for the user. 
Date fields are stored in MM/DD/YYYY format.

## Project Objectives

### Objective 1
```{r ob1}
confirmed_ds<-read.csv("time_series_covid19_confirmed_global.csv", 
                       header=TRUE, stringsAsFactors=FALSE)
deaths_ds<-read.csv("time_series_covid19_deaths_global.csv", 
                    header=TRUE, stringsAsFactors=FALSE)
recovered_ds<-read.csv("time_series_covid19_recovered_global.csv", 
                       header=TRUE, stringsAsFactors=FALSE)

confirmed_ordered<-select(arrange(confirmed_ds, -X1.22.20), 
                          Province.State, Country.Region, X1.22.20)
death_ordered<-select(arrange(deaths_ds, -X1.22.20), 
                      Province.State, Country.Region, X1.22.20)
recovered_ordered<-select(arrange(recovered_ds, -X1.22.20), 
                          Province.State, Country.Region, X1.22.20)

cat("Confirmed Dataset")
head(confirmed_ordered)
cat("Deaths Dataset")
head(death_ordered)
cat("Recovered Dataset")
head(recovered_ordered)

cat(confirmed_ordered[1,1], ", ", confirmed_ordered[1,2], 
    " has the most confirmed cases on the first day. \n", 
    death_ordered[1,1], ", ", death_ordered[1,2], 
    " has the most deaths from the virus on the first day. \n",
    recovered_ordered[1,1], ", ", recovered_ordered[1,2], 
    " has the most recovered cases from the virus on the first day. \n", 
    sep="")


if (confirmed_ordered[1,1] == death_ordered[1,1] && 
    confirmed_ordered[1,1] == recovered_ordered[1,1] && 
    death_ordered[1,1] == recovered_ordered[1,1])
{
  cat(confirmed_ordered[1,1], ", ", confirmed_ordered[1,2], 
    " is the most likely origin of the virus. \n", sep="")
}
```

Based on the data above: Hubei, China is the most likely origin of the virus.  This is based on Hubei, China having by far the most confirmed cases and is the only region with any recoveries or deaths on the first day of data avaliable.  Also, all other regions that have confirmed cases on the first day are regions that are near Hubei. The conditional statement also proves that Hubei is the most likely origin of the virus because it shows that the place with the most deaths, recovered, and confirmed cases on the first day is Hubei.

### Objective 2
```{r ob2}
confirmed_ds<-read.csv("time_series_covid19_confirmed_global.csv", 
                       header=TRUE, stringsAsFactors=FALSE)
recent_ds<-arrange(confirmed_ds[confirmed_ds[,ncol(confirmed_ds)-1] == 0 
                                & confirmed_ds[,ncol(confirmed_ds)] > 0,])

i<-0
# If there are no new cases today loop back to find most recent region
# to have new cases
if (nrow(recent_ds) == 0) {
  while (nrow(recent_ds) == 0) {
    i<-i+1
    recent_ds<-arrange(confirmed_ds[confirmed_ds[,ncol(confirmed_ds)-1-i] == 0 
                                & confirmed_ds[,ncol(confirmed_ds)-i] > 0,])
  }
}

head(select(recent_ds, Province.State, Country.Region, ncol(confirmed_ds)-1-i, 
            ncol(confirmed_ds)-i))

# Vector is small enough that loop is reasonable
for(i in 1:nrow(recent_ds))
{
  if (recent_ds[i,1] == "") {
    cat(recent_ds[i,2], "has recently had their first confirmed case. \n")
  } else {
    if (recent_ds[i,2] == "") {
      cat(recent_ds[i,1], "has recently had their first confirmed case. \n")
    } else {
      cat(recent_ds[i,1], ", ", recent_ds[i,2], 
          " has recently had their first confirmed case. \n", sep="")
    }
  }
}

```

Most recent territories were found by going through the data and selecting the countries that did not have cases before yesterday and had their first cases today.  If there are no regions meeting this check, then each previous day is looked at until there are regions found with new cases.

### Objective 3
```{r ob3}
origin_ds<-arrange(confirmed_ds, -X1.22.20)[1,]
confirmed_ds<-read.csv("time_series_covid19_confirmed_global.csv", 
                       header=TRUE, stringsAsFactors=FALSE)
recent_ds<-arrange(confirmed_ds[confirmed_ds[,ncol(confirmed_ds)-1] == 0 
                                & confirmed_ds[,ncol(confirmed_ds)] > 0,])

i<-0
# If there are no new cases today loop back to find most recent region
# to have new cases
if (nrow(recent_ds) == 0) {
  while (nrow(recent_ds) == 0) {
    i<-i+1
    recent_ds<-arrange(confirmed_ds[confirmed_ds[,ncol(confirmed_ds)-1-i] == 0 
                                & confirmed_ds[,ncol(confirmed_ds)-i] > 0,])
  }
}

# Compute distances from origin
distances<-distm(select(recent_ds, Long, Lat), select(origin_ds, Long, Lat))
# Convert from m to miles
distances<-distances * 0.00062137

# Add distance from origin to dataframe and sort by distance
recent_ds$distance<-distances[,1]
recent_ds<-arrange(recent_ds, distance)

head(select(recent_ds, Province.State, Country.Region, Lat, Long, distance))

# Vector is small enough that loop is reasonable
for (i in 1:nrow(recent_ds)) {
  city<-recent_ds[i, "Province.State"]
  
  # If there is no city use country
  if (city == "") {
    city<-recent_ds[i, "Country.Region"]
  }
  
  cat(city, "is", recent_ds[i, "distance"], 
      "miles away from the virus origin in", 
      paste0(origin_ds[1, "Province.State"], ","), 
      paste0(origin_ds[1, "Country.Region"], "."), "\n")
}

```

### Objective 4

#### Objective 4.1
```{r ob4.1}
# Datasets respresent a cumlative sum by date, so last column represents 
# sumation for region
confirmed_ds<-read.csv("time_series_covid19_confirmed_global.csv", 
                       header=TRUE, stringsAsFactors=FALSE)
confirmed_ds<-select(confirmed_ds, Province.State, 
                     Country.Region, ncol(confirmed_ds))
names(confirmed_ds)[3] <- "confirmed"
deaths_ds<-read.csv("time_series_covid19_deaths_global.csv", 
                    header=TRUE, stringsAsFactors=FALSE)
deaths_ds<-select(deaths_ds, Province.State, 
                  Country.Region, ncol(deaths_ds))
names(deaths_ds)[3] <- "deaths"
recovered_ds<-read.csv("time_series_covid19_recovered_global.csv", 
                       header=TRUE, stringsAsFactors=FALSE)
recovered_ds<-select(recovered_ds, Province.State, 
                     Country.Region, ncol(recovered_ds))
names(recovered_ds)[3] <- "recovered"

# Combine the datasets into one and fill NA with 0
combined_ds<-full_join(confirmed_ds, recovered_ds, 
                       by=c("Province.State", "Country.Region"))
combined_ds<-full_join(combined_ds, deaths_ds, 
                       by=c("Province.State", "Country.Region"))
combined_ds[is.na(combined_ds)] <- 0

# Assignment is unclear if we are to consider state and region or 
# just region. Based on how data is formatted, I think it is cleaner 
# and makes more sence to use region only.  For instance, in confirmed 
# dataset, Canada is broken up by region, but in recovered dataset it 
# uses Canada as a whole.  There are numerous examples of this in
# the data
grouped_ds<-as.data.frame(summarise_each(group_by(
  select(combined_ds, -Province.State), Country.Region), sum))

# compute risk and burden by region
grouped_ds$risk<-grouped_ds$deaths / grouped_ds$recovered
grouped_ds$burden<-grouped_ds$confirmed * grouped_ds$risk

cat("Highest risk scores")
head(arrange(grouped_ds, -risk, -confirmed))
cat("Highest risk scores, that are not infinite")
head(arrange(grouped_ds[grouped_ds$risk != Inf,], -risk, -confirmed))
cat("Lowest Risk Scores")
head(arrange(grouped_ds, risk, confirmed))
cat("Lowest risk scores, that are not zero")
head(arrange(grouped_ds[grouped_ds$risk != 0,], risk, confirmed))

global_confirmed<-sum(grouped_ds$confirmed)
global_deaths<-sum(grouped_ds$deaths)
global_recovered<-sum(grouped_ds$recovered)
global_risk<-global_deaths / global_recovered
global_burden<-global_confirmed * global_risk

cat("Global Data\n", 
    "Confirmed:", global_confirmed, "\n", 
    "Deaths:   ", global_deaths, "\n",
    "Recovered:", global_recovered, "\n",
    "Risk:     ", global_risk, "\n",
    "Burden:   ", global_burden, "\n")

```

Based on how the equation is written, any region which has had at least one person recover and no deaths will have a risk score of zero.  Examples of this can be seen in the "Lowest Risk Scores" table above.  When filtering out risk scores of 0, the regions of lowest risk can be seen in "Lowest risk scores, that are not zero" table above.  Any region that has no recoveries and yet at least one death will have infinite risk.  Examples of this can be seen in the "Highest risk scores" table above.  If filtering out regions that have infinite risk, we see that the regions in the "Highest risk scores, that are not infinite" table above.  When looking at the global score, it seems like the risk is high when considering it represents the people that have recovered versus those who have died.  This value seems especially high when looking at the regions in the "Lowest risk scores, that are not zero" table, but when compared to the "Highest risk scores, that are not infinite" table where the risk scores are extremely high, the global risk seems less significant.  This wide range in risk numbers indicates that while the risk in some regions is extremely high, for the most part, the risk is rather low globally.

Risk assessments like this are important because they are good indicators of where danger is located or help is needed that can be used across many industries.  For example, the travel industry may wish to impose bans on travelling to and from locations of high risk.  The medical field can use these values to determine locations that are in the most need for medical support.  Research fields may also use this data to help identify trends.  For example, if a region has a high amount of recoveries and almost no deaths, i.e. low risk score, it may be worth looking into what kind of treatment they are using in that region and if it could be used in other locations throughout the world. The thing to be careful though is that risk scores may be a little misleading.  For instance, several regions have almost no cases, but one death and no recoveries causing a massive risk score.  Even though these regions have pretty much no cases, they are still seen as extremely risky.  This is why it could be beneficial to filter out the extremes before considering the data as valid.

#### Objective 4.2
```{r ob4.2}
# Datasets respresent a cumlative sum by date, so last column represents 
# sumation for region
confirmed_ds<-read.csv("time_series_covid19_confirmed_global.csv", 
                       header=TRUE, stringsAsFactors=FALSE)
confirmed_ds<-select(confirmed_ds, Province.State, 
                     Country.Region, ncol(confirmed_ds))
names(confirmed_ds)[3] <- "confirmed"
deaths_ds<-read.csv("time_series_covid19_deaths_global.csv", 
                    header=TRUE, stringsAsFactors=FALSE)
deaths_ds<-select(deaths_ds, Province.State, 
                  Country.Region, ncol(deaths_ds))
names(deaths_ds)[3] <- "deaths"
recovered_ds<-read.csv("time_series_covid19_recovered_global.csv", 
                       header=TRUE, stringsAsFactors=FALSE)
recovered_ds<-select(recovered_ds, Province.State, 
                     Country.Region, ncol(recovered_ds))
names(recovered_ds)[3] <- "recovered"

# Combine the datasets into one and fill NA with 0
combined_ds<-full_join(confirmed_ds, recovered_ds, 
                       by=c("Province.State", "Country.Region"))
combined_ds<-full_join(combined_ds, deaths_ds, 
                       by=c("Province.State", "Country.Region"))
combined_ds[is.na(combined_ds)] <- 0

# Group and combine data by region
grouped_ds<-as.data.frame(summarise_each(group_by(
  select(combined_ds, -Province.State), Country.Region), sum))

# compute risk and burden by region
grouped_ds$risk<-grouped_ds$deaths / grouped_ds$recovered
grouped_ds$burden<-grouped_ds$confirmed * grouped_ds$risk

confirmed_tb = kable(arrange(grouped_ds, -confirmed)[1:5,])
deaths_tb = kable(arrange(grouped_ds, -deaths)[1:5,])
recovered_tb = kable(arrange(grouped_ds, -recovered)[1:5,])

cat("Top 5 confirmed regions")
confirmed_tb
cat("Top 5 deaths regions")
deaths_tb
cat("Top 5 recovered regions")
recovered_tb

```

### GitHub Log
#```{bash gitlog} 
#git log --pretty=format:"%nSubject: %s%nAuthor: %aN%nDate: %aD%nBody: %b"
#```

Could not get the above script to work correctly on my system.  This is the output from running the above script directly from the command line:

Subject: Updated responses to be more generic and automatic such that they are created based on data pulled automatically from the table.  Fixed typos and minor bugs.  
Author: 007Stylex007 (Benjamin Kelly)  
Date: Fri, 3 Apr 2020 17:56:46 -0700  
Body:  

Subject: Revised the solutions  
Author: Chanel Fraikin  
Date: Wed, 1 Apr 2020 15:23:30 -0700  
Body:  

Subject: Adding to the initial responses  
Author: Chanel Fraikin  
Date: Tue, 31 Mar 2020 14:18:57 -0700  
Body:  

Subject: Initial attempt at questions 1-4, adding pdf preview of markdown output report  
Author: 007Stylex007 (Benjamin Kelly)  
Date: Mon, 30 Mar 2020 15:12:27 -0700  
Body:  

Subject: Adding confirmed cases dataset and project template  
Author: 007Stylex007 (Benjamin Kelly)  
Date: Fri, 27 Mar 2020 14:15:56 -0700  
Body:  

Subject: Downloaded data  
Author: Chanel Fraikin  
Date: Fri, 27 Mar 2020 13:22:52 -0700  
Body:  

Subject: Update README.md  
Author: cfraikin  
Date: Fri, 27 Mar 2020 13:06:39 -0700  
Body: Added names to the README file  

Subject: Initial commit  
Author: cfraikin  
Date: Fri, 27 Mar 2020 12:59:06 -0700  
Body:  
